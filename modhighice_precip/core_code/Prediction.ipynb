{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% 这个脚本建于已经read并write了所有temp和precip数据的R脚本之后，直接读取所有（100y）的模型输出数据。这一步可以被更改。\n",
    "# 添加必要package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import h5py\n",
    "import os\n",
    "import datetime\n",
    "# some user defined functions\n",
    "import GP_P as GP_P\n",
    "import compute_covariance as cov_matrix\n",
    "\n",
    "### defined forcing data path in the prediction/run.ipynb\n",
    "prediction_input=\"/Users/bo20541/Library/CloudStorage/OneDrive-UniversityofBristol/TONIC-Oligocene/Emulator_Charlie/Emulator/2015_Bristol_5D_v001/orig/Input/2018-08-01 Final report/test_data.1.res\"\n",
    "prediction_output=\"../../prediction/temp_prediction.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read emulator \n",
    "read the sum of 5 parameters in calibration to normalize the new input\n",
    "read the GP list from calibration \n",
    "read the PCA from calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Open the 5 variables sum for standardization\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#################################################\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m nc_data \u001b[38;5;241m=\u001b[39m \u001b[43mnc\u001b[49m\u001b[38;5;241m.\u001b[39mDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../emulator/emul_in_X_5variables_sum.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m var_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(nc_data\u001b[38;5;241m.\u001b[39mvariables\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var_name \u001b[38;5;129;01min\u001b[39;00m var_names:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nc' is not defined"
     ]
    }
   ],
   "source": [
    "# Open the 5 variables sum for standardization\n",
    "#################################################\n",
    "nc_data = nc.Dataset(\"../emulator/emul_in_X_5variables_sum.nc\")\n",
    "var_names = list(nc_data.variables.keys())\n",
    "for var_name in var_names:\n",
    "    globals()[var_name] = nc_data.variables[var_name][:]\n",
    "    print(var_name)\n",
    "\n",
    "\n",
    "# define a function to read the h5 data recursively into a dictionary\n",
    "#----------------------------------------------------------------------\n",
    "def load_h5_as_dict(h5_group):\n",
    "    data = {}\n",
    "    for key, item in h5_group.items():\n",
    "        if isinstance(item, h5py.Group):\n",
    "            # If the item is a group, recurse into it\n",
    "            data[key] = load_h5_as_dict(item)\n",
    "        elif isinstance(item, h5py.Dataset):\n",
    "            # If the item is a dataset, load it as a NumPy array\n",
    "            data[key] = np.array(item)\n",
    "    \n",
    "    # Load attributes as well, if any\n",
    "    for attr_key, attr_value in h5_group.attrs.items():\n",
    "        data[attr_key] = attr_value  # Store attributes as dictionary entries\n",
    "\n",
    "    return data\n",
    "#--------------------------------------------------------------------\n",
    "# Load the HDF5 file and convert it into a dictionary\n",
    "#######################################################\n",
    "with h5py.File(\"../emulator/GPList.h5\", \"r\") as GPList:\n",
    "    EM_Cali = load_h5_as_dict(GPList)\n",
    "print('keys of EM_Cali are:',EM_Cali.keys())\n",
    "print('for each PC in EM_Cali, the keys are:',EM_Cali['PC_01'].keys())\n",
    "\n",
    "# Check if the regression type is not linear\n",
    "if EM_Cali['PC_01']['regress'] != 'linear':\n",
    "    raise ValueError(\"The regression type is not linear. Please check the Clibration.ipynb and add the corresponding callable function.\")\n",
    "\n",
    "\n",
    "nkeep = len(EM_Cali.keys()) # number of PCAs\n",
    "\n",
    "# Load the PCA components \n",
    "##########################\n",
    "# Load the PCA components from a NetCDF file\n",
    "nc_pca = nc.Dataset(\"../emulator/emul_in_Y_PCA.nc\")\n",
    "PCs = {var: nc_pca.variables[var][:] for var in nc_pca.variables}\n",
    "print('keys of PCs are:', PCs.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Input Data for Prediction\n",
    "read the new 5 parameters: orbital parameters, CO2 and ice sheet parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the input data (orbital parameters and CO2 values) contains the values across all years\n",
    "x_full = pd.read_csv(prediction_input, sep='\\s+', header=None)  # Read table\n",
    "\n",
    "# Get the number of experiments\n",
    "nexp = x_full.shape[0] - 1 # Get the number of years\n",
    "index_nexp = np.arange(nexp) # Create an index for the number of years\n",
    "\n",
    "# Normalize input variables. Starts from 1 to skip the header\n",
    "var1 = x_full.iloc[1:,0].values.astype(float) / co2_sum          # Normalize `V1` by `co2_sum`\n",
    "var2 = x_full.iloc[1:,1].values.astype(float) / obliquity_sum    # Normalize `V2` by `obliquity_sum`\n",
    "var3 = x_full.iloc[1:,2].values.astype(float) / esinw_sum        # Normalize `V3` by `esinw_sum`\n",
    "var4 = x_full.iloc[1:,3].values.astype(float) / ecosw_sum        # Normalize `V4` by `ecosw_sum`\n",
    "var5 = x_full.iloc[1:,4].values.astype(float) / ice_sum          # Normalize ice volume by `ice_sum`\n",
    "\n",
    "# make vector of all input variables at the current year\n",
    "x = np.array([var1, var2, var3, var4, var5])\n",
    "print('shape of x:', x.shape)\n",
    "print(\"the 5 input variable for prediction are:\", x_full.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulisaztion of the input data to help understanding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(index_nexp, var1*co2_sum, label='CO2')\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('CO2')\n",
    "plt.title('Scatter plot of input CO2 values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get an example of the keys in the GP_P output\n",
    "tmp_var = GP_P.GP_P(EM_Cali, PCs, x[:,0])\n",
    "predic_var = {key: [] for key in tmp_var.keys()}\n",
    "\n",
    "for n in range(nexp):\n",
    "    predic_var_tmp = GP_P.GP_P(EM_Cali, PCs, x[:,n])\n",
    "    for key in predic_var.keys():\n",
    "        predic_var[key].append(predic_var_tmp[key])\n",
    "\n",
    "print('keys of predic_var are:',predic_var.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *optional: visulization of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# 创建 figure 和轴对象\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 经纬度网格\n",
    "X, Y = np.meshgrid(PCs['lon'], PCs['lat'])\n",
    "\n",
    "# 创建 Basemap（用于绘制海陆分界线）\n",
    "m = Basemap(projection='cyl', lon_0=180, resolution='c', ax=ax)\n",
    "m.drawcoastlines()\n",
    "\n",
    "# 初始绘图\n",
    "contour = ax.contourf(X, Y, predic_var['mean'][0], cmap='coolwarm', levels=np.linspace(-60, 60, 41))\n",
    "cbar = plt.colorbar(contour, ax=ax, orientation='vertical')\n",
    "cbar.set_label('predic_var (°C)')\n",
    "contour.collections\n",
    "\n",
    "# 初始化函数\n",
    "def init():\n",
    "\tax.set_title('Time Step: 0')\n",
    "\treturn contour.collections\n",
    "\n",
    "# 更新函数\n",
    "def update(frame):\n",
    "\tax.clear()\n",
    "\tm.drawcoastlines()\n",
    "\t\n",
    "\t# 更新等高线图\n",
    "\tcontour = ax.contourf(X, Y, predic_var['mean'][frame], cmap='coolwarm', levels=np.linspace(-60, 60, 41))\n",
    "\tax.set_title(f'Time Step: {frame}\\n'\n",
    "\t\t\t\t f'CO2: {x_full.iloc[frame+1,0]}, '\n",
    "\t\t\t\t f'Obliquity: {x_full.iloc[frame+1,1]}, '\n",
    "\t\t\t\t f'esinw: {x_full.iloc[frame+1,2]}, '\n",
    "\t\t\t\t f'ecosw: {x_full.iloc[frame+1,3]}, '\n",
    "\t\t\t\t f'Ice: {x_full.iloc[frame+1,4]}')\n",
    "\treturn contour.collections\n",
    "\n",
    "# 创建动画\n",
    "ani = FuncAnimation(fig, update, frames=range(nexp-900), init_func=init, blit=False)\n",
    "\n",
    "# 在 Jupyter Notebook 中显示动画\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the results into NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if the NetCDF file already exists, if so, backup it\n",
    "if os.path.exists(prediction_output):\n",
    "    now = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "    os.rename(prediction_output, prediction_output[:-3] + \"_\" + now + \".nc\")\n",
    "\n",
    "ncnew = nc.Dataset(prediction_output, \"w\")\n",
    "\n",
    "lat = PCs[\"lat\"]\n",
    "lon = PCs[\"lon\"]\n",
    "\n",
    "# Define dimensions\n",
    "ncnew.createDimension(\"lon\", len(lon))\n",
    "ncnew.createDimension(\"lat\", len(lat))\n",
    "ncnew.createDimension(\"time\", nexp)\n",
    "\n",
    "# Define variables:'mean', 'var', 'means', 'variances'\n",
    "mean = ncnew.createVariable(\"mean\", \"f4\", (\"time\", \"lat\", \"lon\"))\n",
    "mean.units = \"1\"\n",
    "mean.long_name = \"Predicted Variable Mean field\"\n",
    "\n",
    "var = ncnew.createVariable(\"variance\", \"f4\", (\"time\", \"lat\", \"lon\"))\n",
    "var.units = \"1\"\n",
    "var.long_name = \"Predicted Variable variance field\"\n",
    "\n",
    "# Define coordinate variables\n",
    "latitudes = ncnew.createVariable(\"latitude\", \"f4\", (\"lat\",))\n",
    "longitudes = ncnew.createVariable(\"longitude\", \"f4\", (\"lon\",))\n",
    "time = ncnew.createVariable(\"time\", \"i4\", (\"time\",))\n",
    "\n",
    "# Assign attributes to coordinate variables\n",
    "latitudes.units = \"degrees_north\"\n",
    "latitudes.long_name = \"Latitude\"\n",
    "longitudes.units = \"degrees_east\"\n",
    "longitudes.long_name = \"Longitude\"\n",
    "time.units = \"1\"\n",
    "time.long_name = \"Time\"\n",
    "# Add global attributes\n",
    "ncnew.description = \"This NetCDF file contains predicted data based on emulator outputs.\"\n",
    "\n",
    "ncnew.history = f\"Created on {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "ncnew.source = \"Input forcing is: \"+prediction_input\n",
    "\n",
    "# Write data to coordinate variables\n",
    "latitudes[:] = lat\n",
    "longitudes[:] = lon\n",
    "time[:] = index_nexp\n",
    "\n",
    "# Write data to variables\n",
    "mean[:, :, :] = predic_var[\"mean\"]\n",
    "var[:, :, :] = predic_var[\"var\"]\n",
    "\n",
    "# Close the NetCDF file\n",
    "ncnew.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_process",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
