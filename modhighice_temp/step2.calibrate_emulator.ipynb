{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% this script is used to calibrate the emulator, dont need to change anything, just run it will be fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% 这个脚本建于已经read并write了所有temp和precip数据的R脚本之后，直接读取所有（100y）的模型输出数据。这一步可以被更改。\n",
    "% Update 250219: 在后期prediction中，需要对X input 的5个变量做标准化，原本使用了CO2_sum等，现在改为使用CO2.mean 以及 CO2.std\n",
    "# 添加必要package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%autoreload\n",
    "#%reload_ext autoreload\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from netCDF4 import Dataset\n",
    "import os\n",
    "import h5py\n",
    "# some user defined functions\n",
    "from core_code.pca import PCA\n",
    "from core_code.GP_C import GP_C\n",
    "import core_code.compute_covariance as cov_mat\n",
    "\n",
    "\n",
    "data_path = 'training_data/'\n",
    "#os.chdir('../' + path)\n",
    "emu_path = 'emulator/'\n",
    "if not os.path.exists(emu_path):\n",
    "    os.makedirs(emu_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we keep  15  PCs, \n",
      "the hyper parameter shape: (6, 15)\n",
      "every PC has the same set of HP, an example:\n",
      "l.co2       1.003084\n",
      "l.esinw     6.907880\n",
      "l.ecosw     7.499054\n",
      "l.obl       5.460205\n",
      "l.icevol    0.290289\n",
      "nugget      0.050143\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# number of Principal Components to take into account\n",
    "nkeep = 15\n",
    "\n",
    "# length scale and nugget hyperparameter values\n",
    "# higher length scale means smoother functions, higher nugget means more noise\n",
    "\n",
    "hp = pd.DataFrame({\n",
    "    'l.co2': [1.003084] * nkeep,\n",
    "    'l.esinw': [6.907880]* nkeep,\n",
    "    'l.ecosw': [7.499054] * nkeep,\n",
    "    'l.obl': [5.460205] * nkeep,\n",
    "    'l.icevol': [0.290289] * nkeep,\n",
    "    'nugget': [0.050143] * nkeep\n",
    "})\n",
    "\n",
    "# The way the pe_c routine takes hp is not okay: it requires a matrix shaped this way\n",
    "hp = hp.T\n",
    "\n",
    "print(\"we keep \",nkeep,\" PCs, \")\n",
    "print(\"the hyper parameter shape:\",hp.shape)\n",
    "print(\"every PC has the same set of HP, an example:\")\n",
    "print(hp.iloc[:, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  读取五个变量并且normalize -地球轨道，CO2，ice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  读取五个变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['co2', 'obliquity', 'esinw', 'ecosw', 'ice'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 读取文件\n",
    "cont_paramdat = pd.read_csv(data_path+'emul_in_X.res', sep='\\s+', header=0)\n",
    "\n",
    "# 获取数据维度\n",
    "cont_param_dim = cont_paramdat.shape\n",
    "\n",
    "# 打印列名以检查是否存在 \n",
    "print(cont_paramdat.columns)\n",
    "\n",
    "# 提取各列\n",
    "co2 = cont_paramdat['co2']\n",
    "obliquity = cont_paramdat['obliquity']\n",
    "esinw = cont_paramdat['esinw']\n",
    "ecosw = cont_paramdat['ecosw']\n",
    "ice = cont_paramdat['ice']\n",
    "\n",
    "\n",
    "####!! Here's for standardization only to fit with Charlie's code\n",
    "cont_paramdats = pd.read_csv(data_path+'emul_in_X_Char.res', sep='\\s+', header=0)\n",
    "cont_param_dims = cont_paramdats.shape\n",
    "co2s = cont_paramdats['co2']\n",
    "obliquitys = cont_paramdats['obliquity']\n",
    "esinws = cont_paramdats['esinw']\n",
    "ecosws = cont_paramdats['ecosw']\n",
    "ices = cont_paramdats['ice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalized数据并新建一个DataFrame保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122 entries, 0 to 121\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   co2_ppm_norm    122 non-null    float64\n",
      " 1   obliquity_norm  122 non-null    float64\n",
      " 2   esinw_norm      122 non-null    float64\n",
      " 3   ecosw_norm      122 non-null    float64\n",
      " 4   ice_norm        122 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 4.9 KB\n",
      "   co2_ppm_norm  obliquity_norm  esinw_norm  ecosw_norm  ice_norm\n",
      "0     -0.243952       -0.478087   -1.512807    1.571177  0.296477\n",
      "1      0.275264       -0.432065    1.197083    0.547123  0.296477\n",
      "2      0.121845       -0.754213   -1.063874    1.862467  0.296477\n",
      "3     -0.182021        1.117310    2.305386    0.115632  0.296477\n",
      "4     -0.478311       -0.324683   -1.329523    0.435053  0.296477\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import xarray as xr\n",
    "import datetime\n",
    "\n",
    "\n",
    "### log the CO2 and standardize all the parameters -----\n",
    "### updata 16th Jan 2025: log the CO2, and standardize all the parameters instead of just dividing by the sum\n",
    "# Log transform the CO2 data\n",
    "co2 = np.log(co2)\n",
    "co2s = np.log(co2s)\n",
    "\n",
    "##!!!note here, in order to fits Charlies's code, we need to introduce both mod and modlow X to standardize the data\n",
    "##!!!need to check the code in the future emulator training.\n",
    "# Standardize all the parameters\n",
    "paras_normalized = pd.DataFrame({\n",
    "    'co2_ppm_norm': (co2 - co2s.mean()) / co2s.std(),\n",
    "    'obliquity_norm': (obliquity - obliquitys.mean()) / obliquitys.std(),\n",
    "    'esinw_norm': (esinw - esinws.mean()) / esinws.std(),\n",
    "    'ecosw_norm': (ecosw - ecosws.mean()) / ecosws.std(),\n",
    "    'ice_norm': (ice - ices.mean()) / ices.std()\n",
    "})\n",
    "\n",
    "paras_normalized.info()\n",
    "\n",
    "# ##------ old code ------ \n",
    "# obliquity_sum = obliquity.sum()\n",
    "# esinw_sum = esinw.sum()\n",
    "# ecosw_sum = ecosw.sum()\n",
    "# co2_sum = co2.sum()\n",
    "# ice_sum = ice.sum()\n",
    "\n",
    "# paras_normalized = pd.DataFrame(columns=[ 'co2_ppm_norm', 'esinw_norm', 'ecosw_norm', 'obliquity_norm', 'ice_norm'])\n",
    "# paras_normalized['co2_ppm_norm'] = co2 / co2_sum\n",
    "# paras_normalized['esinw_norm'] = esinw / esinw_sum\n",
    "# paras_normalized['ecosw_norm'] = ecosw / ecosw_sum\n",
    "# paras_normalized['obliquity_norm'] = obliquity / obliquity_sum\n",
    "# paras_normalized['ice_norm'] = ice / ice_sum\n",
    "\n",
    "# paras_normalized.info()\n",
    "\n",
    "# # Create a dataset with the sums of the parameters\n",
    "# data = {\n",
    "#     'co2_sum': co2_sum,\n",
    "#     'obliquity_sum': obliquity_sum,\n",
    "#     'esinw_sum': esinw_sum,\n",
    "#     'ecosw_sum': ecosw_sum,\n",
    "#     'ice_sum': ice_sum\n",
    "# }\n",
    "\n",
    "# Save the mean and std of CO2 and other parameters\n",
    "data = {\n",
    "    'co2_mean': co2s.mean(),\n",
    "    'co2_std': co2s.std(),\n",
    "    'obliquity_mean': obliquitys.mean(),\n",
    "    'obliquity_std': obliquitys.std(),\n",
    "    'esinw_mean': esinws.mean(),\n",
    "    'esinw_std': esinws.std(),\n",
    "    'ecosw_mean': ecosws.mean(),\n",
    "    'ecosw_std': ecosws.std(),\n",
    "    'ice_mean': ices.mean(),\n",
    "    'ice_std': ices.std()\n",
    "}\n",
    "\n",
    "# Convert the dictionary to an xarray Dataset\n",
    "ds = xr.Dataset(data)\n",
    "\n",
    "# backup the file if it already exists\n",
    "if os.path.exists(emu_path+\"emul_in_X_5variables_mean_std.nc\"):\n",
    "    now = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "    os.rename(emu_path+\"emul_in_X_5variables_mean_std.nc\", emu_path+\"emul_in_X_5variables_mean_std_\" + now + \".nc\")\n",
    "\n",
    "# Save the dataset to a NetCDF file，用作后面的prediction的inputd normalize\n",
    "ds.to_netcdf(emu_path+'emul_in_X_5variables_mean_std.nc')\n",
    "\n",
    "print(paras_normalized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取模型输出数据（temp，precip) 12x100x201x201 - month x exp x lat x lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取emul_in_Y数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature data shape: (122, 73, 96)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Open the NetCDF file\n",
    "temp_file = Dataset(data_path+'emul_in_Y.nc', mode='r')  # 'r' for read mode\n",
    "# Print the file information\n",
    "#print(\"Variables:\", temp_file.variables.keys())\n",
    "# Extract data from a specific variable (e.g., 'temperature')\n",
    "temp_all = temp_file.variables['var'][:,:,:]\n",
    "lat = temp_file.variables['latitude'][:]\n",
    "lon = temp_file.variables['longitude'][:]\n",
    "#print(\"temperature data shape:\",temp_tmp.shape)\n",
    "# Close the file\n",
    "temp_file.close()\n",
    "\n",
    "print(\"temperature data shape:\",temp_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进行PCA处理\n",
    " 产生几个components（可以理解为维度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA results saved to emul_in_Y_PCA.nc\n",
      "the information of the PCA results is: dict_keys(['mean', 'PCA', 'amps', 'd', 'scaled_amps', 'rvm'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform PCA for Y data and store the results\n",
    "# backup the file if it already exists\n",
    "if os.path.exists(emu_path+\"emul_in_Y_PCA.nc\"):\n",
    "    now = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "    os.rename(emu_path+\"emul_in_Y_PCA.nc\", emu_path+\"emul_in_Y_PCA_\" + now + \".nc\")\n",
    "\n",
    "temp_pca = PCA(temp_all[ :, :, :].transpose(1, 2, 0), nkeep)\n",
    "\n",
    "# Convert the PCA results to an xarray Dataset\n",
    "pca_data = xr.Dataset({\n",
    "    'mean': (['lat', 'lon'], temp_pca['mean']),\n",
    "    'PCA': (['lat', 'lon','pc'], temp_pca['PCA']),\n",
    "    'scaled_amps': (['nexp', 'pc'], temp_pca['scaled_amps']),\n",
    "    'amps': (['nexp', 'pc'], temp_pca['amps']),\n",
    "    'd': (['nexp'], temp_pca['d']),\n",
    "    'lat': (['lat'], lat),\n",
    "    'lon': (['lon'], lon)\n",
    "})\n",
    "\n",
    "# Save the PCA results to a NetCDF file\n",
    "pca_data.to_netcdf(emu_path+'emul_in_Y_PCA.nc')\n",
    "\n",
    "print(\"PCA results saved to emul_in_Y_PCA.nc\")\n",
    "print('the information of the PCA results is:', temp_pca.keys())\n",
    "\n",
    "# mean: mean of each grid\n",
    "# PCA: the original PCA results 主成分\n",
    "# scaled_amps: scaled amplitude of each PC。\n",
    "# amps: amplitude of each PC 每个月份数据的主成分得分。\n",
    "# d: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进行GP处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对于cov_mat function的画图说明（以助于理解）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## test the covariance matrix\n",
    "# %autoreload 2\n",
    "# import compute_covariance as cov_mat\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# ## need to be modified in the cov_mat function\n",
    "# R = cov_mat.cov_mat(hp.iloc[:, 0], paras_normalized, paras_normalized)\n",
    "\n",
    "# # a example to visualize the function of cov_mat\n",
    "# x = np.arange(1, len(paras_normalized['co2_ppm_norm']) + 1)\n",
    "\n",
    "# # First figure\n",
    "# plt.figure()\n",
    "# sns.regplot(x=x, y=paras_normalized['co2_ppm_norm'])\n",
    "# plt.title('a example of normalized co2')\n",
    "# plt.show()\n",
    "\n",
    "# if 'RR' in locals():\n",
    "#     plt.figure()\n",
    "#     plt.contourf(x, x, RR[:, :, 3], cmap='seismic')\n",
    "#     plt.colorbar()\n",
    "#     plt.plot(x, x, 'k--', label='X=Y')  # Add X=Y line\n",
    "#     plt.title('transformed covariance matrix of CO2')\n",
    "#     plt.xlabel('X-axis')\n",
    "#     plt.ylabel('Y-axis')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "# else:\n",
    "#     print(\"Variable 'RR' is not read from cov_mat.\")\n",
    "\n",
    "# # Third figure\n",
    "# plt.figure()\n",
    "# plt.contourf(x, x, R[:, :], cmap='seismic')\n",
    "# plt.colorbar()\n",
    "# plt.plot(x, x, 'k--', label='X=Y')  # Add X=Y line\n",
    "# plt.title('transformed covariance of 5 parameters')\n",
    "# plt.xlabel('X-axis')\n",
    "# plt.ylabel('Y-axis')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP - Calibration\n",
    " get the E_list which contains mean, PCA ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['betahat', 'sigma_hat_2', 'R', 'Rt', 'muX', 'X', 'Y', 'lambda', 'e', 'funcmu', 'R1tX', 'log_REML', 'log_pen_REML', 'covar', 'nbrr'])\n",
      "{'l.co2': 1.003084, 'l.esinw': 6.90788, 'l.ecosw': 7.499054, 'l.obl': 5.460205, 'l.icevol': 0.290289, 'nugget': 0.050143, 'epsilon': 1.0}\n",
      "shape of X is (122, 5)\n",
      "shape of Y is (122,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define the regress method\n",
    "regress = 'linear'\n",
    "\n",
    "\n",
    "# backup the file if it already exists\n",
    "if os.path.exists(emu_path+\"GPList.h5\"):\n",
    "    now = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "    os.rename(emu_path+\"GPList.h5\", emu_path+\"GPList_\" + now + \".h5\")\n",
    "\n",
    "# Print a summary of temp_pca\n",
    "# Create a new group for each 'nkeep' in the HDF5 file\n",
    "with h5py.File(emu_path+\"GPList.h5\", \"w\") as file: \n",
    "    # loop of nkeep of PCAs\n",
    "    # amps[n,nkeep] \n",
    "    for i in range(nkeep):\n",
    "        GPList = GP_C(paras_normalized, temp_pca['amps'][:, i], hp.iloc[:, i], regress=regress)\n",
    "        group = file.create_group(f\"PC_{i+1:02}\")\n",
    "        for key, value in GPList.items():\n",
    "            if isinstance(value, np.ndarray):\n",
    "                group.create_dataset(key, data=value)  # Save matrix\n",
    "            else:\n",
    "                group.attrs[key] = str(value)  # Convert non-array types to strings before saving as attributes\n",
    "            group.attrs['regress'] = regress  # Store regress as a string\n",
    "\n",
    "# check the keys of the dictionary\n",
    "print(GPList.keys())\n",
    "print(GPList['lambda'])\n",
    "print(\"shape of X is\",GPList['X'].shape)\n",
    "print(\"shape of Y is\",GPList['Y'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_process",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
